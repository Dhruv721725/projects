{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruv721725/projects/blob/main/p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üëó Fashion-MNIST ‚Üí CNN ‚Üí TensorFlow Lite (Colab Starter)\n",
        "\n",
        "This notebook teaches you the full pipeline:\n",
        "1) Understand the key building blocks (activation, bias, convolution, pooling, etc.)\n",
        "2) Load the **Fashion-MNIST** dataset (10 clothing classes)\n",
        "3) Build & train a **CNN** in TensorFlow/Keras\n",
        "4) Evaluate and visualize performance\n",
        "5) Convert to **TensorFlow Lite** (with quantization) and test inference\n",
        "\n",
        "> Tip: Go to **Runtime ‚Üí Change runtime type ‚Üí GPU** for faster training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîé Concept Cheatsheet (Simple & Practical)\n",
        "\n",
        "- **Tensor / Shape**: Multi‚Äëdimensional array. For images here: `(batch, 28, 28, 1)`.\n",
        "- **Bias**: A trainable constant added to each neuron‚Äôs weighted sum. Let‚Äôs a neuron shift the activation threshold.\n",
        "- **Activation Function**: Turns the linear sum into a non‚Äëlinear output.\n",
        "  - **ReLU**: `max(0, x)` ‚Äì fast, avoids vanishing gradients. Most common in CNNs.\n",
        "  - **LeakyReLU**: Like ReLU but small slope for negatives to avoid dead neurons.\n",
        "  - **Sigmoid**: Outputs (0,1). Good for binary outputs, not hidden CNN layers.\n",
        "  - **Tanh**: Outputs (‚àí1,1). Less common in modern CNNs.\n",
        "  - **Softmax**: Converts logits to probabilities across classes (used in the final layer).\n",
        "- **Convolution (Conv2D)**: Learns small kernels/filters (e.g., 3√ó3) that slide over the image to detect patterns.  \n",
        "  - **Kernel/Filter**: Small learnable matrix. Number of filters = number of feature maps learned.\n",
        "  - **Stride**: Step size while sliding (usually 1).\n",
        "  - **Padding**: `\"same\"` keeps size; `\"valid\"` shrinks size.\n",
        "- **Pooling**: Downsamples feature maps (e.g., **MaxPooling2D(2√ó2)**) to reduce size and help translation invariance.\n",
        "- **Batch Normalization**: Normalizes activations to stabilize & speed up training.\n",
        "- **Dropout**: Randomly drops a fraction of activations during training to reduce overfitting.\n",
        "- **Loss**: What we minimize. For multi‚Äëclass classification with integer labels, use **SparseCategoricalCrossentropy**.\n",
        "- **Optimizer**: How we update weights. **Adam** works well by default.\n",
        "- **Learning Rate (LR)**: Step size for updates. Too high = diverge, too low = slow. We use a scheduler.\n",
        "- **Metrics**: Accuracy, confusion matrix to see per‚Äëclass performance.\n",
        "- **Overfitting Control**: Data augmentation, dropout, early stopping, L2 regularization.\n",
        "- **TFLite**: Lightweight runtime for on‚Äëdevice inference (works offline). We‚Äôll convert our Keras model to `.tflite`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ‚úÖ Setup & Imports (run this first)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "\n",
        "# GPU check\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"GPUs available:\", gpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Class Names\n",
        "class_names = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "]\n",
        "class_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üì• Load Fashion-MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize to [0,1] and add channel dimension\n",
        "x_train = (x_train / 255.0).astype(\"float32\")[..., np.newaxis]  # (N, 28, 28, 1)\n",
        "x_test  = (x_test  / 255.0).astype(\"float32\")[..., np.newaxis]\n",
        "\n",
        "print(\"Train:\", x_train.shape, y_train.shape)\n",
        "print(\"Test :\", x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üëÄ Peek at a few samples\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(x_train[i].squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[y_train[i]])\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîÄ Train / Validation Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
        ")\n",
        "print(\"Train:\", x_tr.shape, y_tr.shape, \"| Val:\", x_val.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîß tf.data pipelines (+ light augmentation)\n",
        "batch_size = 128\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def augment(image, label):\n",
        "    # For grayscale 28x28, keep augmentations subtle\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    # Small random brightness/contrast\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image, label\n",
        "\n",
        "ds_train = tf.data.Dataset.from_tensor_slices((x_tr, y_tr))\\\n",
        "    .shuffle(10_000)\\\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\\\n",
        "    .batch(batch_size)\\\n",
        "    .prefetch(AUTOTUNE)\n",
        "\n",
        "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\\\n",
        "    .batch(batch_size)\\\n",
        "    .prefetch(AUTOTUNE)\n",
        "\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\\n",
        "    .batch(batch_size)\\\n",
        "    .prefetch(AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üß† Build a CNN (Conv ‚Üí BN ‚Üí ReLU ‚Üí Pool ‚Üí Dropout blocks)\n",
        "def conv_block(x, filters):\n",
        "    x = layers.Conv2D(filters, (3,3), padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "inputs = layers.Input(shape=(28,28,1))\n",
        "x = conv_block(inputs, 32)\n",
        "x = conv_block(x, 32)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = conv_block(x, 64)\n",
        "x = conv_block(x, 64)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "x = conv_block(x, 128)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)  # softmax for class probs\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üèÉ Train with EarlyStopping + LR scheduler\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2, min_lr=1e-5, monitor=\"val_loss\"),\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=15,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìà Plot training curves\n",
        "hist = history.history\n",
        "plt.figure()\n",
        "plt.plot(hist[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(hist[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ‚úÖ Evaluate & Confusion Matrix\n",
        "test_loss, test_acc = model.evaluate(ds_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_prob = model.predict(ds_test)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix'):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(cm, class_names, normalize=False, title=\"Confusion Matrix (Counts)\")\n",
        "plot_confusion_matrix(cm, class_names, normalize=True, title=\"Confusion Matrix (Normalized)\")\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üíæ Save Keras model & labels\n",
        "model.save(\"fashion_mnist_cnn.h5\")\n",
        "\n",
        "with open(\"label_map.txt\", \"w\") as f:\n",
        "    for i, name in enumerate(class_names):\n",
        "        f.write(f\"{i}:{name}\\n\")\n",
        "\n",
        "print(\"Saved: fashion_mnist_cnn.h5 and label_map.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîÑ Convert to TFLite (Dynamic Range Quantization)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # dynamic-range quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"fashion_mnist_cnn_dynamic.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Saved: fashion_mnist_cnn_dynamic.tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üî¨ Convert to TFLite (Full Integer INT8 Quantization)\n",
        "def representative_data_gen():\n",
        "    for i in range(200):  # few hundred samples are enough\n",
        "        img = x_tr[i]\n",
        "        img = np.expand_dims(img, axis=0).astype(np.float32)\n",
        "        yield [img]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "int8_tflite = converter.convert()\n",
        "with open(\"fashion_mnist_cnn_int8.tflite\", \"wb\") as f:\n",
        "    f.write(int8_tflite)\n",
        "\n",
        "print(\"Saved: fashion_mnist_cnn_int8.tflite (full integer)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üß™ Test TFLite Inference (Dynamic model)\n",
        "# This test uses the dynamic-quantized TFLite model.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"fashion_mnist_cnn_dynamic.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Pick a test image\n",
        "idx = 0\n",
        "img = x_test[idx:idx+1]  # shape (1, 28, 28, 1)\n",
        "\n",
        "# If input type is not float32, cast accordingly\n",
        "inp_type = input_details[0]['dtype']\n",
        "img_for_infer = img.astype(inp_type)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], img_for_infer)\n",
        "interpreter.invoke()\n",
        "pred = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "pred_class = np.argmax(pred)\n",
        "\n",
        "plt.imshow(img[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(f\"True: {class_names[y_test[idx]]} | Pred: {class_names[pred_class]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ (Optional) Collecting Your Own Fashion Data\n",
        "If you want to extend/retrain with custom clothing images, use this folder layout:\n",
        "```\n",
        "dataset/\n",
        "  train/\n",
        "    T-shirt_top/     img001.jpg ...\n",
        "    Trouser/\n",
        "    Pullover/\n",
        "    Dress/\n",
        "    Coat/\n",
        "    Sandal/\n",
        "    Shirt/\n",
        "    Sneaker/\n",
        "    Bag/\n",
        "    Ankle_boot/\n",
        "  val/\n",
        "    T-shirt_top/\n",
        "    ...\n",
        "  test/\n",
        "    ...\n",
        "```\n",
        "Tips:\n",
        "- Keep **backgrounds simple** and **lighting consistent**.\n",
        "- Aim for **600‚Äì1,000 images per class** to start (you can grow later).\n",
        "- Use **data augmentation** during training (flips, brightness, contrast).\n",
        "- Ensure **no overlap** between the same **physical items** across train/val/test.\n",
        "- If images are RGB and larger, you can resize to 64√ó64 or 96√ó96 and adjust the CNN input shape.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN75GEO9zgtK3/oAf52HVzL",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
